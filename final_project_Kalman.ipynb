{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_project_Kalman.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z-Zy5R377k8C","colab_type":"text"},"source":["# Welcome to the Final Project!\n","\n","Course: https://thinkautonomous.ai/obstacle-tracking\n","\n","In this project, you will learn to associate bounding boxes on multiple frames using the Hungarian Algorithm!\n","\n","\n","You will work on 3 aspects of the **multi-object tracker**:\n","\n","*   Use YOLO and launch an object detection algorithm\n","*   Use The Hungarian Algorithm and associate the boxes\n","*   Improve the algorithm to avoid false positives and false negatives\n"]},{"cell_type":"markdown","metadata":{"id":"VbG8vs9u8OOg","colab_type":"text"},"source":["This is a part included to link your Google Colab file (.ipynb) to your Google Drive folder.\n","\n","If you don't work on Colab, you won't need these."]},{"cell_type":"code","metadata":{"id":"ZPW9hbcuYxqO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"ok","timestamp":1597755606032,"user_tz":-120,"elapsed":27015,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"eedde73a-590a-4b76-d796-d67a3bec75c5"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","os.chdir(\"/content/drive/My Drive/Think Autonomous/SDC Course/Tracking\")\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","association_hungarian.ipynb\t     Images\t\t     yolo.ipynb\n","association_hungarian_Starter.ipynb  Output\t\t     yolo_nms.py\n","final_project.ipynb\t\t     __pycache__\t     yolo_Starter.ipynb\n","final_project_Kalman.ipynb\t     Tracking.gslides\t     Yolov3\n","final_project_Kalman_Starter.ipynb   yolo_for_tracking_2.py\n","final_project_Starter.ipynb\t     yolo_for_tracking.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZcNCkytu3ykt","colab_type":"text"},"source":["# 1 - Detection\n","\n","In order to make multi-object tracking work, we will need to do a detection step. The tracking will heavily rely on the detector, it better be good.\n","\n","We will choose the [YOLO algorithm](https://pjreddie.com/darknet/yolo/) that is both accurate and fast.\n","\n","<img src=\"https://miro.medium.com/max/1446/1*YpNE9OQeshABhBgjyEXlLA.png\" width=\"500\">\n","\n","\n","Eventually, we want bounding box detection\n","\n","<img src=\"https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png\" width=\"500\">\n"]},{"cell_type":"markdown","metadata":{"id":"UStSXSC3RKue","colab_type":"text"},"source":["## Import Libraries and Test Images\n","\n","Let's import the libraries and test images.<p>\n","I took a video and wrote a short script to take a picture every 7 frame of the image. Instead of working at **60 FPS** (recording frame rate), consider you have an algorithm working at 60/7 or about **9 frame per second**.<p>_\n","\n","**Why the cut ?**<p>\n","YOLO is very fast, it can work at 60 FPS.\n","For tracking to be a bit challenging, let's not have 99% IOU every time."]},{"cell_type":"code","metadata":{"id":"9n24pesxqdTP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755609862,"user_tz":-120,"elapsed":1200,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["### Imports\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import copy\n","import pickle\n","import cv2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJ6bw_4Rqh3T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755611868,"user_tz":-120,"elapsed":2313,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["### Load the Images\n","dataset_images = pickle.load(open('Images/images_tracking.p', \"rb\"))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"duVgFEYHfRsM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755611871,"user_tz":-120,"elapsed":1748,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def visualize_images(input_images):\n","    fig=plt.figure(figsize=(100,100))\n","\n","    for i in range(len(input_images)):\n","        fig.add_subplot(1, len(input_images), i+1)\n","        plt.imshow(input_images[i])\n","    plt.show()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ref3X-llqt4o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"1YO_FP4icHyzJgUN-rqdsrnTm3mdvKZoo"},"executionInfo":{"status":"ok","timestamp":1597755617841,"user_tz":-120,"elapsed":7189,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"ade39e80-499f-43fb-e9f7-34eb07de316f"},"source":["visualize_images(dataset_images)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"9P5YlyD3UZmq","colab_type":"text"},"source":["## Run Initial Obstacle Detection - Modify the YOLO file\n","\n","We will need to modify the original yolo.py file. Go to this file, **duplicate it**, and **modify the duplicate online** using Google Drive's text editor. <p>_\n","\n","**What modifications should you do?**<p>\n","The current *inference()* function outputs an image.\n","To work with the hungarian algorithm, we will need the bounding box.<p>\n","* **Modify the postprocess()** function as well as the **inference() function** to **return the bounding box**.\n","* Then, we will only work with the original image and the bounding boxes\n","* Call the new file **yolo_for_tracking.py**\n"," and import it"]},{"cell_type":"code","metadata":{"id":"S2QETWZhM3j8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1597755632144,"user_tz":-120,"elapsed":17966,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"c2725a82-02c3-42b4-d03b-7c7bde2e5661"},"source":["### Run obstacle detection for the images\n","from yolo_for_tracking import *\n","\n","result_images = [] # Empty list for output images\n","result_boxes = [] # Empty list for output boxes\n","\n","# Initiliaze an object detector\n","detector = YOLO()\n","images = copy.deepcopy(dataset_images)\n","\n","# For every image, run a detector using the inference() function\n","for img in images:\n","    result, boxes = detector.inference(img)\n","    result_images.append(result)\n","    result_boxes.append(boxes)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bHvtTDrEVr_7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"19-qjgGgY3x3Evkl7Tqm0Q3b7j3VoQjSK"},"executionInfo":{"status":"ok","timestamp":1597755638486,"user_tz":-120,"elapsed":23964,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"4354333f-87cf-460e-9749-a4b903451bfb"},"source":["# Print the results and the detected boxes\n","visualize_images(result_images)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"MUIbq5XkXGaY","colab_type":"text"},"source":["## One Obstacle - One Color\n","**Last Step!** <p>\n","We now one one color per bounding box! All cars in blue is useless! <p>\n","We will create an Obstacle class that we will modify.\n","Each detected obstacle should have:\n","* an id\n","* a current bounding box\n","* a previous bounding box<p>_\n","\n","**In the end, we will draw a bounding box based on the id.** <p>\n","If the id changes, the color will change also."]},{"cell_type":"code","metadata":{"id":"a99w3HIF1MLL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755639101,"user_tz":-120,"elapsed":587,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["class Obstacle():\n","    def __init__(self, idx, box):\n","        \"\"\"\n","        Init function. The obstacle must have an id and a box.\n","        \"\"\"\n","        self.idx = idx\n","        self.box = box"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ly04QA_gOMJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755639102,"user_tz":-120,"elapsed":577,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def id_to_color(idx):\n","    \"\"\"\n","    Random function to convert an id to a color\n","    Do what you want here but keep numbers below 255\n","    \"\"\"\n","    blue = idx*5 % 256\n","    green = idx*36 %256\n","    red = idx*23 %256\n","    return (red, green, blue)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWacVf_5gShC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755639317,"user_tz":-120,"elapsed":784,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def main():\n","    \"\"\"\n","    Main function.\n","    You already ran the detector on all 9 images. The variable is result_boxes.\n","    Use this to assign an id and draw a rectangle based on the id.\n","    \"\"\"\n","    idx = 0\n","    obstacles = []\n","    result_images_2 = copy.deepcopy(dataset_images) # Copy the image without modifying the dataset\n","    for j, boxes in enumerate(result_boxes): # loop through all images\n","        for i, box in enumerate(boxes): # loop through all boxes\n","            obs = Obstacle(idx, box)\n","            left, top, width, height = box\n","            right = left+width\n","            bottom = top+height\n","            cv2.rectangle(result_images_2[j], (left, top), (right, bottom), id_to_color(idx+i), thickness=10)\n","            idx +=1\n","            obstacles.append(obs)\n","    return result_images_2\n","\n","result_images_2 = main()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Eq18R7WYXkD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"1Torw5nNzG2zFMY1cem3hy3UPa2SMTxDB"},"executionInfo":{"status":"ok","timestamp":1597755646264,"user_tz":-120,"elapsed":7718,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"1ff5f49d-9250-4cc0-8cf6-6ff1fd576c00"},"source":["## Print the results\n","visualize_images(result_images_2)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"NmsuPGWAbHvd","colab_type":"text"},"source":["We did it!<p>...<p>\n","\n","But as you can see, the colors are not kept along the images. **We don't have active tracking yet**!"]},{"cell_type":"markdown","metadata":{"id":"BCEQikXa30Cx","colab_type":"text"},"source":["# 2 - Association\n","\n","We now have a detection algorithm working! Congratulations!\n","The next step is to **match the detections** from one frame to another and **keep the color along the 9 images**.<p>\n","It should be dynamic and **work no matter the number of images**. In the end, we'll apply **this algorithm on a video**.\n","\n","Eventually, we'll want a good association system\n","\n","![Texte alternatif…](https://miro.medium.com/proxy/0*yN9MllhmuglJORss.png)"]},{"cell_type":"markdown","metadata":{"id":"jD-ZE43rcVvW","colab_type":"text"},"source":["## Metrics\n","\n","The first thing we'll need is to define a metric!\n","\n","* If you **don't want a big challenge**, the **IOU cost** will do just fine!\n","* If you want a **medium challenge**, you can try to **implement [this paper](https://arxiv.org/pdf/1709.03572.pdf)**. Read carefully page 19-20 and try to implement these costs with IOU. It will filter out incoherent boxes.\n","* If you want the **biggest challenge**, try to **code [Deep SORT](https://arxiv.org/pdf/1703.07402.pdf)** and associate Deep Convolutional features to it. <p>\n","\n","In the end, you should have a **single number in the cost matrix**. And it should be representative of the cost, like IOU is."]},{"cell_type":"markdown","metadata":{"id":"n-grOk3_hHSc","colab_type":"text"},"source":["### IOU COST"]},{"cell_type":"code","metadata":{"id":"0NpEcw8L5HnS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755646265,"user_tz":-120,"elapsed":7700,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def convert_data(box):\n","    \"\"\"\n","    Convert data from (x1,y1, w, h) to (x1,y1,x2,y2)\n","    \"\"\"\n","    x1 = box[0]\n","    x2 = box[0] + box[2]\n","    y1 = box[1]\n","    y2 = box[1]+box[3]\n","    return x1,y1,x2,y2\n","\n","def box_iou(box1, box2):\n","    \"\"\"\n","    Computer Intersection Over Union cost\n","    \"\"\"\n","    box1 = convert_data(box1)\n","    box2 = convert_data(box2)\n","    xA = max(box1[0], box2[0])\n","    yA = max(box1[1], box2[1])\n","    xB = min(box1[2], box2[2])\n","    yB = min(box1[3], box2[3])\n","\n","    inter_area = max(0, xB - xA + 1) * max(0, yB - yA + 1) #abs((xi2 - xi1)*(yi2 - yi1))\n","    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n","    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1) #abs((box1[3] - box1[1])*(box1[2]- box1[0]))\n","    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1) #abs((box2[3] - box2[1])*(box2[2]- box2[0]))\n","    union_area = (box1_area + box2_area) - inter_area\n","    # compute the IoU\n","    iou = inter_area/float(union_area)\n","    return iou"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XRVXGejWhL_S","colab_type":"text"},"source":["### Exponential, Linear, And IOU Costs\n","\n","Use this paper to code the solution: https://arxiv.org/pdf/1709.03572.pdf"]},{"cell_type":"code","metadata":{"id":"OK7LfLBthi8r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755646266,"user_tz":-120,"elapsed":7693,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":[" from math import sqrt, exp\n","\n","def check_division_by_0(value, epsilon=0.01):\n","    if value < epsilon:\n","        value = epsilon\n","    return value\n","\n","def hungarian_cost(old_box, new_box, iou_thresh = 0.3, linear_thresh = 10000, exp_thresh = 0.5):\n","        w1 = 0.5\n","        w2 = 1.5\n","        (_, h, w, _) = np.array(dataset_images).shape\n","        # IOU COST\n","        iou_cost = box_iou(old_box, new_box)\n","        \n","        ### Sanchez-Matilla et al COST\n","        Q_dist = sqrt(pow(w,2)+pow(h,2)) # First real-life Pythagore use in your life\n","        Q_shape = w*h\n","        distance_term = Q_dist/check_division_by_0(sqrt(pow(old_box[0] - new_box[0], 2)+pow(old_box[1] -new_box[1],2)))\n","        shape_term = Q_shape/check_division_by_0(sqrt(pow(old_box[2] - new_box[2], 2)+pow(old_box[3] - new_box[3],2)))\n","        linear_cost = distance_term*shape_term\n","\n","        ## YUL et al COST\n","        a= (old_box[0] - new_box[0])/check_division_by_0(old_box[2])\n","        a_2 = pow(a,2)\n","        b = (old_box[1] - new_box[1])/check_division_by_0(old_box[3])\n","        b_2 = pow(b,2)\n","        ab = (a_2+b_2)*w1*(-1)\n","        c = abs(old_box[3] - new_box[3])/(old_box[3]+new_box[3])\n","        d = abs(old_box[2]-new_box[2])/(old_box[2]+new_box[2])\n","        cd = (c+d)*w2*(-1)\n","        exponential_cost = exp(ab)*exp(cd)\n","\n","        if (iou_cost >= iou_thresh and linear_cost>=linear_thresh and exponential_cost>=exp_thresh):\n","            return iou_cost\n","        else :\n","            return 0"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6CvRBXgjWK2","colab_type":"text"},"source":["## The Hungarian Algorithm\n","We can now use the previous code from the workshop to track bounding boxes!\n","\n","* Create an **associate()** function that takes **two lists of boxes** (time t-1 and time t) and that outputs **the matches, the new detections, and the unmatched tracks**."]},{"cell_type":"code","metadata":{"id":"SXwhIsjd6kFY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755646267,"user_tz":-120,"elapsed":7687,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["from scipy.optimize import linear_sum_assignment\n","\n","def associate(old_boxes, new_boxes):\n","    \"\"\"\n","    old_boxes will represent the former bounding boxes (at time 0)\n","    new_boxes will represent the new bounding boxes (at time 1)\n","    Function goal: Define a Hungarian Matrix with IOU as a metric and return, for each box, an id\n","    \"\"\"\n","    # Define a new IOU Matrix nxm with old and new boxes\n","    iou_matrix = np.zeros((len(old_boxes),len(new_boxes)),dtype=np.float32)\n","\n","    # Go through boxes and store the IOU value for each box \n","    # You can also use the more challenging cost but still use IOU as a reference for convenience (use as a filter only)\n","    for i,old_box in enumerate(old_boxes):\n","        for j,new_box in enumerate(new_boxes):\n","            iou_matrix[i][j] = box_iou(old_box, new_box)\n","            #iou_matrix[i][j] = hungarian_cost(old_box, new_box)\n","\n","    # Call for the Hungarian Algorithm\n","    hungarian_row, hungarian_col = linear_sum_assignment(-iou_matrix)\n","    hungarian_matrix = np.array(list(zip(hungarian_row, hungarian_col)))\n","\n","    # Create new unmatched lists for old and new boxes\n","    matches, unmatched_detections, unmatched_trackers = [], [], []\n","\n","    # Go through the Hungarian Matrix, if matched element has IOU < threshold (0.3), add it to the unmatched \n","    # Else: add the match    \n","    for h in hungarian_matrix:\n","        if(iou_matrix[h[0],h[1]]<0.3):\n","            unmatched_trackers.append(old_boxes[h[0]])\n","            unmatched_detections.append(new_boxes[h[1]])\n","        else:\n","            matches.append(h.reshape(1,2))\n","    \n","    if(len(matches)==0):\n","        matches = np.empty((0,2),dtype=int)\n","    else:\n","        matches = np.concatenate(matches,axis=0)\n","    \n","    # Go through old boxes, if no matched detection, add it to the unmatched_old_boxes\n","    for t,trk in enumerate(old_boxes):\n","\t    if(t not in hungarian_matrix[:,0]):\n","\t\t    unmatched_trackers.append(trk)\n","    \n","    # Go through new boxes, if no matched tracking, add it to the unmatched_new_boxes\n","    for d, det in enumerate(new_boxes):\n","        if(d not in hungarian_matrix[:,1]):\n","                unmatched_detections.append(det)\n","    \n","    return matches, unmatched_detections,unmatched_trackers"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_TtyGCW5hvW","colab_type":"text"},"source":["## Main Loop"]},{"cell_type":"code","metadata":{"id":"m4uClkOsM7Mg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755646267,"user_tz":-120,"elapsed":7679,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def main(input_image):\n","    \"\"\"\n","    Receives an images\n","    Outputs the result image, and a list of obstacle objects \n","    \"\"\"\n","    global stored_obstacles # Will be used to keep track of obstacles information\n","    global idx # Will be used to keep track of id information\n","    # Run obstacle detection\n","    image = copy.deepcopy(input_image)\n","    _, out_boxes = yolo.inference(input_image)\n","    # First iteration: Simply create obstacles and draw them\n","    if (idx == 0):\n","        stored_obstacles = []\n","        for i, box in enumerate(out_boxes): # For all detected boxes\n","            obs = Obstacle(idx, box) # Create an obstacle\n","            left, top, right, bottom = convert_data(box) # Move to x1,y1,x2,y2\n","            cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness=10) # Draw the box on the image with ids\n","            image = cv2.putText(image, str(obs.idx),(left - 10,top -10),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness=4)\n","            stored_obstacles.append(obs) # Put every created obstacle in the final list                \n","            idx +=1 # Increase the id for every box\n","        return image, stored_obstacles\n","\n","    elif (idx != 0): # In case we already have obstacles from previous frame, work on association\n","        ## Before calling associate, we must create a list of old obstacles\n","        old_obstacles = [obs.box for obs in stored_obstacles] # Simply get the boxes\n","        matches, unmatched_detections, unmatched_tracks = associate(old_obstacles, out_boxes) # Associate the obstacles\n","        new_obstacles = []\n","\n","        # For every match, change the obstacle value\n","        # Assign the id to the matched id\n","        # Assign the box to the new box\n","        for match in matches:\n","            obs = Obstacle(stored_obstacles[match[0]].idx, out_boxes[match[1]])\n","            new_obstacles.append(obs)\n","        \n","        # Loop through all unmatched detections and add these as obstacles\n","        for new_obs in unmatched_detections:\n","            idx+=1\n","            obs = Obstacle(idx, new_obs)\n","            new_obstacles.append(obs)\n","        \n","        # For every obstacle, draw on the image and return it\n","        for i, obs in enumerate(new_obstacles):\n","            left, top, right, bottom = convert_data(obs.box)\n","            cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness=10)\n","            image = cv2.putText(image, str(obs.idx),(left - 10,top - 10),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness=4)                \n","        stored_obstacles = copy.deepcopy(new_obstacles)\n","        return image, stored_obstacles"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cVeLR137YGf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"12ecu8wXb3yZWjr6yhpQGEajvkqQPyFNp"},"executionInfo":{"status":"ok","timestamp":1597755661025,"user_tz":-120,"elapsed":22429,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"07a6b738-5aee-4aff-9f29-9faa85966294"},"source":["### Call the main loop\n","\n","yolo = YOLO()\n","idx = 0\n","\n","fig=plt.figure(figsize=(100,100))\n","\n","result_images_3 = copy.deepcopy(dataset_images)\n","\n","out_imgs = []\n","\n","for i in range(len(result_images_3)):\n","    out_img, stored_obstacles = main(result_images_3[i])\n","    out_imgs.append(out_img)\n","    fig.add_subplot(1, len(result_images_3), i+1)\n","    plt.imshow(out_imgs[i])\n","\n","plt.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"ftb6lKOSBJup","colab_type":"text"},"source":["# 3 - Improvements\n"]},{"cell_type":"markdown","metadata":{"id":"bDlc5Kw9uMlT","colab_type":"text"},"source":["### Changing the Non Maxima Suppression formula\n","\n","In OpenCV DNN, NMS (Non Maxima Suppression) is computer per class, insteaf of on the whole list. For that reason, we may arrive at unwanted results:\n","![](https://user-images.githubusercontent.com/25801568/79720833-01a88180-82ea-11ea-993b-8accd6b7fcc1.png)\n","\n","I have found a new Non-Maxima Suppression formula we can use [on PyImageSearch's page](https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/).\n","\n","We have to adapt it:\n","\n","*   We have (x1,y1,w,h) and we the function takes (x1,y1, x2, y2)\n","*   That's it!\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Gs6FmgoYMl8X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124,"output_embedded_package_id":"12syYCHBfqrMBrNGpRIz9BpxOi8P4RAGZ"},"executionInfo":{"status":"ok","timestamp":1597755677003,"user_tz":-120,"elapsed":38382,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"56fba794-7b9c-48f3-ce2e-e0cd807778a0"},"source":["from yolo_nms import *\n","\n","yolo = YOLO()\n","idx = 0\n","\n","fig=plt.figure(figsize=(100,100))\n","\n","result_images_3 = copy.deepcopy(dataset_images)\n","\n","out_imgs = []\n","\n","for i in range(len(result_images_3)):\n","    out_img, stored_obstacles = main(result_images_3[i])\n","    out_imgs.append(out_img)\n","    fig.add_subplot(1, len(result_images_3), i+1)\n","    plt.imshow(out_imgs[i])\n"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"GxC6_jbjMif_","colab_type":"text"},"source":["### Using Age\n","\n","\n","We now have a pretty good tracker! <p>\n","One thing that is not very good is that it relies solely on the detector.\n","If we miss the detection, we miss everything. <p>\n","\n","In this part, we'll introduce two ideas:\n","* False Positive\n","* False Negative<p>\n","\n","A **false positive** means that you detected an obstacle that shouldn't detect.<p>\n","We'll solve it by introducing a **MIN_HIT_STREAK** variable. If the detector detects something once, it is not displayed. If it **detects it twice in a row**, or 3 times in a row (thanks to matching), it is displayed.\n","\n","A **false negative** means that you didn't detect an obstacle that should have been detected.<p>\n","We'll solve it by introducing a **MAX_AGE** variable. If an obstacle is suddently unmatched, we **keep displaying** it. If it is unmatched again, or more times, we remove it."]},{"cell_type":"code","metadata":{"id":"SvLcyXVrBgeq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755683372,"user_tz":-120,"elapsed":853,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["MIN_HIT_STREAK = 2\n","MAX_UNMATCHED_AGE = 3"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeBeNMRWQHG8","colab_type":"text"},"source":["**Obstacle Class** <p>\n","Let's redefine the Obstacle class to include these values\n","Every obstacle should have:\n","* an id\n","* a box\n","* an age (number of times matched)\n","* an unmatched frame number (number of times unmatched)"]},{"cell_type":"code","metadata":{"id":"QyUG4St3QDTZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755683961,"user_tz":-120,"elapsed":637,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["class Obstacle():\n","    def __init__(self, idx, box, age=1, unmatched_age=0):\n","        self.idx = idx\n","        self.box = box\n","        self.age = age\n","        self.unmatched_age = unmatched_age"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNK1OJVWQj3G","colab_type":"text"},"source":["**Main Loop**<p>\n","Now we can redefine the main loop\n","We simply add conditions to display or not an obstacle"]},{"cell_type":"code","metadata":{"id":"l5UU7mgTQjR2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755684966,"user_tz":-120,"elapsed":644,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def main(input_image):\n","    \"\"\"\n","    Receives an images\n","    Outputs the result image, and a list of obstacle objects \n","    \"\"\"\n","    global stored_obstacles # Will be used to keep track of obstacles information\n","    global idx # Will be used to keep track of id information\n","    # Run obstacle detection\n","    image = copy.deepcopy(input_image)\n","    _, out_boxes = yolo.inference(input_image)\n","    \n","    # What we will do will be very similar but we have a second list of obstacles that answer to the conditions\n","    # On first iteration, we only create obstacles with age=1\n","    if (idx == 0):\n","        stored_obstacles = []\n","        for i, box in enumerate(out_boxes):\n","            obs = Obstacle(idx, box) # Create an obstacle with age=1\n","            stored_obstacles.append(obs)                \n","            idx +=1\n","        return image\n","    \n","    # On this case, if the obstacle has already been matched, we display it depending on the MIN_HIT_STREAK variable\n","    elif (idx != 0): # In case we already have obstacles from previous frame, work on association\n","        ## Before calling associate, we must create a list of old obstacles\n","        old_obstacles = [obs.box for obs in stored_obstacles] # Simply get the boxes\n","        matches, unmatched_detections, unmatched_tracks = associate(old_obstacles, out_boxes) # Associate the obstacles\n","        \n","        selected_obstacles = []\n","        # Loop through all matches and add these as obstacles\n","        new_obstacles = []\n","        for match in matches:\n","            obs = Obstacle(stored_obstacles[match[0]].idx, out_boxes[match[1]], stored_obstacles[match[0]].age +1) # Increase the age by 1\n","            new_obstacles.append(obs)\n","            if obs.age >= MIN_HIT_STREAK:\n","                selected_obstacles.append(obs)\n","        \n","        # Loop through all unmatched detections and add these as obstacles\n","        for new_obs in unmatched_detections:\n","            idx +=1\n","            obs = Obstacle(idx, new_obs)\n","            new_obstacles.append(obs)\n","            if obs.age >= MIN_HIT_STREAK:\n","                selected_obstacles.append(obs)\n","\n","        for i, old_obs in enumerate(unmatched_tracks):\n","            if (stored_obstacles[i].box == old_obs):\n","                obs = stored_obstacles[i] \n","                obs.unmatched_age +=1\n","                if obs.unmatched_age <= MAX_UNMATCHED_AGE:\n","                    selected_obstacles.append(obs)\n","\n","        # Draw on selected obstacles only\n","        for i, obs in enumerate(selected_obstacles):\n","            left, top, right, bottom = convert_data(obs.box)\n","            cv2.rectangle(image, (left, top), (right, bottom), id_to_color(obs.idx), thickness=10)\n","            image = cv2.putText(image, str(obs.idx),(left,top),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness=4)                \n","\n","        stored_obstacles = copy.deepcopy(new_obstacles)\n","        return image"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"nE45f0_JQdGQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"1KpBERWHpNcFeoBleEiw1R-HYPVgHcCWH"},"executionInfo":{"status":"ok","timestamp":1597755703421,"user_tz":-120,"elapsed":18480,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"111fbe4e-39c5-4b16-84e6-0885e818a83a"},"source":["yolo = YOLO()\n","idx = 0\n","\n","fig=plt.figure(figsize=(100,100))\n","\n","result_images_3 = copy.deepcopy(dataset_images)\n","\n","out_imgs = []\n","\n","for i in range(len(result_images_3)):\n","    out_img = main(result_images_3[i])\n","    out_imgs.append(out_img)\n","    fig.add_subplot(1, len(result_images_3), i+1)\n","    plt.imshow(out_imgs[i])\n","\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"yqugyO2tC6fS","colab_type":"text"},"source":["# 4 - Kalman Filters\n","\n","It is now time to introduce Kalman Filters to this project.\n","Kalman Filters will help predict the future position of a bounding box, so that the association will always match in the future.\n","\n","We'll use a Kalman Filters that has a state of 4 variables: x, y, w, h. <p>\n","These are the values returned by the YOLO algorithm.\n","\n","\n","The process will be the following\n","*   Detect bounding boxes\n","*   Associate it with the previous predictions\n","*   Predict the next position of each box\n","<p>Repeat <p>\n","The association is made with the prediction from t-1.\n","\n","Alright!"]},{"cell_type":"code","metadata":{"id":"SMzEMxY-EYWs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1597756364428,"user_tz":-120,"elapsed":4821,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"42428a72-7229-4010-89b9-037f5fb5f8ff"},"source":["!pip install filterpy"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: filterpy in /usr/local/lib/python3.6/dist-packages (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.18.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->filterpy) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"whoxzWnvEn0w","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755710800,"user_tz":-120,"elapsed":7339,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["from filterpy.kalman import KalmanFilter\n","from scipy.linalg import block_diag\n","from filterpy.common import Q_discrete_white_noise\n","import time\n","\n","def FourDimensionsKF(R_std=10, Q_std=0.01):\n","    \"\"\" Create first order Kalman filter. \n","    Specify R and Q as floats.\"\"\"\n","    kf = KalmanFilter(dim_x=8, dim_z=4)\n","    kf.F = np.array([[1, 1, 0,  0, 0, 0, 0, 0],\n","                    [0,  1, 0,  0, 0, 0, 0, 0],\n","                    [0,  0, 1, 1, 0, 0, 0, 0],\n","                    [0,  0, 0,  1, 0, 0, 0, 0],\n","                     [0, 0, 0, 0, 1, 1, 0, 0],\n","                     [0, 0, 0, 0, 0, 1, 0, 0],\n","                      [0, 0, 0, 0, 0, 0, 1, 1],\n","                     [0, 0, 0, 0, 0, 0, 0, 1]])\n","\n","    kf.P *= 1000\n","    kf.R[2:, 2:] *= R_std\n","    kf.Q[-1, -1] *= Q_std\n","    kf.Q[4:, 4:] *= Q_std\n","    return kf"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4Wwd-8dL5b7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755710801,"user_tz":-120,"elapsed":7330,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["# The Obstacle Class will now have Kalman Filter values\n","\n","class Obstacle():\n","    def __init__(self, idx, box, time, age=1, unmatched_age=0):\n","        self.idx = idx\n","        self.box = box\n","        self.age = age\n","        self.unmatched_age = unmatched_age\n","        self.time = time\n","        self.kf = FourDimensionsKF()\n","        self.kf.x = np.array([box[0], 0, box[1], 0, box[2], 0, box[3], 0])\n","        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0, 0],\n","                             [0, 0, 1, 0, 0, 0, 0, 0],\n","                             [0, 0, 0, 0, 1, 0, 0, 0],\n","                             [0, 0, 0, 0, 0, 0, 1, 0]])"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrR7HCabHNd5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755710802,"user_tz":-120,"elapsed":7322,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def get_obs_from_mean(mean):\n","    return [mean[0], mean[2], mean[4], mean[6]]"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfnOM9GJtMTR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755975295,"user_tz":-120,"elapsed":827,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def return_F_with_dt(dt):\n","    #dt = 7./60. #IMAGE MODE WITH 1/7 IMAGE\n","    dt = 1./25. #VIDEO MODE\n","    #dt = 1\n","    return np.array([\n","                [1, dt, 0,  0, 0, 0, 0, 0],\n","                [0,  1, 0,  0, 0, 0, 0, 0],\n","                [0,  0, 1, dt, 0, 0, 0, 0],\n","                [0,  0, 0,  1, 0, 0, 0, 0],\n","                [0, 0, 0, 0, 1, dt, 0, 0],\n","                [0, 0, 0, 0, 0, 1, 0, 0],\n","                [0, 0, 0, 0, 0, 0, 1, dt],\n","                [0, 0, 0, 0, 0, 0, 0, 1]])"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeY7u_2Mq8mH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597755977443,"user_tz":-120,"elapsed":636,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["def main(input_image):\n","    \"\"\"\n","    Receives an images\n","    Outputs the result image, and a list of obstacle objects \n","    \"\"\"\n","    global stored_obstacles\n","    global idx\n","    global yolo\n","    \n","    #print(\"Starting new loop ...\")\n","    image = copy.deepcopy(input_image)\n","    _, out_boxes = yolo.inference(input_image)\n","    current_time = time.time()\n","    #print(\"Detected Boxes\")\n","    #print(out_boxes)\n","    \n","    # First Detection, Initialize a Kalman Filter per Bounding Box\n","    if (idx == 0):\n","        stored_obstacles = []\n","        for i, box in enumerate(out_boxes):\n","            obs = Obstacle(idx, box, current_time)\n","            stored_obstacles.append(obs)\n","            idx +=1\n","            #print(\"Initialized Kalman Filter\")\n","            #print(obs.kf.x)\n","        return input_image\n","    \n","    # Not First Detection, Match and KF\n","    elif (idx != 0):                \n","        # Match between old obstacles and new using Hungarian Algorithm\n","        old_boxes = [obs.box for obs in stored_obstacles]\n","        matches, unmatched_detections, unmatched_tracks = associate(old_boxes, out_boxes)\n","\n","        selected_obstacles = []\n","        new_obstacles = []\n","\n","        # For Matched Obstacles, Update & Predict the next position; store in Box for future match\n","        for match in matches:\n","            obs = stored_obstacles[match[0]] # Take the former obstacle and its ID\n","            obs.age +=1 # Increment the age by 1\n","            \n","            # Update\n","            measurement = out_boxes[match[1]]\n","            #print(\"Value before update\")\n","            #print(obs.kf.x)\n","            \n","            obs.kf.update(np.array(measurement))\n","            #print(\"Updated Value: \")\n","            #print(get_obs_from_mean(obs.kf.x_post))\n","\n","            # Prediction\n","            F = return_F_with_dt(current_time - obs.time)\n","            obs.kf.F = F\n","            obs.kf.predict()\n","            obs.time = current_time\n","            #print(\"New Prediction: \")\n","            #print(get_obs_from_mean(obs.kf.x_prior))\n","            # Update for future Match\n","            obs.box = get_obs_from_mean(obs.kf.x)\n","            \n","            #print(\"Matched Prediction: \", obs.box, \" and: \",out_boxes[match[1]])\n","\n","            new_obstacles.append(obs)\n","            if obs.age >= MIN_HIT_STREAK:\n","                selected_obstacles.append(obs)\n","\n","        # For Unmatched Detections, Do the same as for idx = 0\n","        for new_obs in unmatched_detections:\n","            idx +=1\n","            obs = Obstacle(idx, new_obs, current_time)\n","            new_obstacles.append(obs)\n","            if obs.age >= MIN_HIT_STREAK:\n","                selected_obstacles.append(obs)\n","\n","        # For Unmatched Tracks, Just Predict using dt\n","        for i, old_obs in enumerate(unmatched_tracks):\n","            if stored_obstacles[i].box == old_obs:\n","                #obs = Obstacle(idx, old_obs, current_time)\n","                obs = stored_obstacles[i]\n","                F = return_F_with_dt(current_time - obs.time)\n","                obs.time = current_time\n","                obs.kf.F = F\n","                obs.kf.predict()\n","                obs.box = get_obs_from_mean(obs.kf.x)\n","                #print(\"Unmatched Track; Prediction:\")\n","                #print(obs.box)\n","                obs.unmatched_age +=1\n","                if obs.unmatched_age <= MAX_UNMATCHED_AGE:\n","                    selected_obstacles.append(obs)\n","\n","        # Draw on selected obstacles only\n","        for i, obs in enumerate(selected_obstacles):\n","            left, top, right, bottom = convert_data(obs.box)\n","            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), id_to_color(obs.idx), thickness=10)\n","            image = cv2.putText(image, str(obs.idx),(int(left),int(top)),cv2.FONT_HERSHEY_SIMPLEX, 1,id_to_color(obs.idx),thickness=4)                \n","        stored_obstacles = copy.deepcopy(new_obstacles)\n","        return image\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBaz4r-466of","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108,"output_embedded_package_id":"1yTRFXBIBGwb8Guq-KUi6Nma2-NgbryBt"},"executionInfo":{"status":"ok","timestamp":1597755729551,"user_tz":-120,"elapsed":26049,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"7861c2f8-a6ec-44cf-9eef-3eb3f15d64d5"},"source":["yolo = YOLO()\n","\n","idx = 0\n","\n","fig=plt.figure(figsize=(100,100))\n","\n","result_images_3 = copy.deepcopy(dataset_images)\n","\n","out_imgs = []\n","\n","for i in range(len(result_images_3)):\n","    out_img = main(result_images_3[i])\n","    out_imgs.append(out_img)\n","    fig.add_subplot(1, len(result_images_3), i+1)\n","    plt.imshow(out_imgs[i])\n","\n","plt.show()"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Vnjp_IpHF5Hn","colab_type":"text"},"source":["# Video\n","\n","\n","Now is the time to run on a video. Import the video_0 file and run it in Paris!\n","If you have GPU, it's even better.\n","Otherwise, use a subclip function to run it only on the first seconds"]},{"cell_type":"code","metadata":{"id":"WAjA7cW8p0gw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597756158358,"user_tz":-120,"elapsed":173648,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}},"outputId":"06c81065-d647-4e0d-dbce-f22c0eec0d73"},"source":["from moviepy.editor import VideoFileClip\n","idx = 0\n","detector = YOLO()\n","#video_file = \"/content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Images/video_0.MOV\"\n","#video_file = \"/content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Images/MOT16-13-raw.mp4\" #25 FPS\n","video_file = \"/content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Images/MOT16-14-raw.mp4\" #25 FPS\n","clip = VideoFileClip(video_file).subclip(0,5)\n","white_clip = clip.fl_image(main)\n","%time white_clip.write_videofile(\"/content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Output/movie_track_kf_out.mp4\",audio=False)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[MoviePy] >>>> Building video /content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Output/movie_track_kf_out.mp4\n","[MoviePy] Writing video /content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Output/movie_track_kf_out.mp4\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/126 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/126 [00:01<02:39,  1.28s/it]\u001b[A\n","  2%|▏         | 2/126 [00:02<02:40,  1.30s/it]\u001b[A\n","  2%|▏         | 3/126 [00:03<02:40,  1.31s/it]\u001b[A\n","  3%|▎         | 4/126 [00:05<02:39,  1.31s/it]\u001b[A\n","  4%|▍         | 5/126 [00:06<02:39,  1.32s/it]\u001b[A\n","  5%|▍         | 6/126 [00:07<02:38,  1.32s/it]\u001b[A\n","  6%|▌         | 7/126 [00:09<02:38,  1.33s/it]\u001b[A\n","  6%|▋         | 8/126 [00:10<02:36,  1.32s/it]\u001b[A\n","  7%|▋         | 9/126 [00:11<02:34,  1.32s/it]\u001b[A\n","  8%|▊         | 10/126 [00:13<02:33,  1.32s/it]\u001b[A\n","  9%|▊         | 11/126 [00:14<02:31,  1.32s/it]\u001b[A\n"," 10%|▉         | 12/126 [00:15<02:31,  1.33s/it]\u001b[A\n"," 10%|█         | 13/126 [00:17<02:30,  1.33s/it]\u001b[A\n"," 11%|█         | 14/126 [00:18<02:28,  1.33s/it]\u001b[A\n"," 12%|█▏        | 15/126 [00:19<02:27,  1.33s/it]\u001b[A\n"," 13%|█▎        | 16/126 [00:21<02:25,  1.33s/it]\u001b[A\n"," 13%|█▎        | 17/126 [00:22<02:23,  1.32s/it]\u001b[A\n"," 14%|█▍        | 18/126 [00:23<02:22,  1.32s/it]\u001b[A\n"," 15%|█▌        | 19/126 [00:25<02:21,  1.32s/it]\u001b[A\n"," 16%|█▌        | 20/126 [00:26<02:19,  1.32s/it]\u001b[A\n"," 17%|█▋        | 21/126 [00:27<02:19,  1.33s/it]\u001b[A\n"," 17%|█▋        | 22/126 [00:29<02:18,  1.33s/it]\u001b[A\n"," 18%|█▊        | 23/126 [00:30<02:16,  1.33s/it]\u001b[A\n"," 19%|█▉        | 24/126 [00:31<02:15,  1.33s/it]\u001b[A\n"," 20%|█▉        | 25/126 [00:33<02:13,  1.32s/it]\u001b[A\n"," 21%|██        | 26/126 [00:34<02:11,  1.32s/it]\u001b[A\n"," 21%|██▏       | 27/126 [00:35<02:10,  1.32s/it]\u001b[A\n"," 22%|██▏       | 28/126 [00:37<02:09,  1.32s/it]\u001b[A\n"," 23%|██▎       | 29/126 [00:38<02:07,  1.32s/it]\u001b[A\n"," 24%|██▍       | 30/126 [00:39<02:07,  1.33s/it]\u001b[A\n"," 25%|██▍       | 31/126 [00:41<02:05,  1.32s/it]\u001b[A\n"," 25%|██▌       | 32/126 [00:42<02:03,  1.32s/it]\u001b[A\n"," 26%|██▌       | 33/126 [00:43<02:02,  1.32s/it]\u001b[A\n"," 27%|██▋       | 34/126 [00:44<02:01,  1.32s/it]\u001b[A\n"," 28%|██▊       | 35/126 [00:46<01:59,  1.32s/it]\u001b[A\n"," 29%|██▊       | 36/126 [00:47<01:58,  1.31s/it]\u001b[A\n"," 29%|██▉       | 37/126 [00:48<01:57,  1.32s/it]\u001b[A\n"," 30%|███       | 38/126 [00:50<01:55,  1.32s/it]\u001b[A\n"," 31%|███       | 39/126 [00:51<01:55,  1.32s/it]\u001b[A\n"," 32%|███▏      | 40/126 [00:52<01:53,  1.32s/it]\u001b[A\n"," 33%|███▎      | 41/126 [00:54<01:52,  1.32s/it]\u001b[A\n"," 33%|███▎      | 42/126 [00:55<01:50,  1.32s/it]\u001b[A\n"," 34%|███▍      | 43/126 [00:56<01:52,  1.35s/it]\u001b[A\n"," 35%|███▍      | 44/126 [00:58<01:50,  1.35s/it]\u001b[A\n"," 36%|███▌      | 45/126 [00:59<01:49,  1.35s/it]\u001b[A\n"," 37%|███▋      | 46/126 [01:00<01:47,  1.34s/it]\u001b[A\n"," 37%|███▋      | 47/126 [01:02<01:45,  1.34s/it]\u001b[A\n"," 38%|███▊      | 48/126 [01:03<01:44,  1.34s/it]\u001b[A\n"," 39%|███▉      | 49/126 [01:05<01:43,  1.35s/it]\u001b[A\n"," 40%|███▉      | 50/126 [01:06<01:42,  1.35s/it]\u001b[A\n"," 40%|████      | 51/126 [01:07<01:41,  1.35s/it]\u001b[A\n"," 41%|████▏     | 52/126 [01:09<01:41,  1.37s/it]\u001b[A\n"," 42%|████▏     | 53/126 [01:10<01:39,  1.37s/it]\u001b[A\n"," 43%|████▎     | 54/126 [01:11<01:38,  1.37s/it]\u001b[A\n"," 44%|████▎     | 55/126 [01:13<01:37,  1.37s/it]\u001b[A\n"," 44%|████▍     | 56/126 [01:14<01:35,  1.37s/it]\u001b[A\n"," 45%|████▌     | 57/126 [01:15<01:34,  1.37s/it]\u001b[A\n"," 46%|████▌     | 58/126 [01:17<01:33,  1.38s/it]\u001b[A\n"," 47%|████▋     | 59/126 [01:18<01:32,  1.38s/it]\u001b[A\n"," 48%|████▊     | 60/126 [01:20<01:30,  1.37s/it]\u001b[A\n"," 48%|████▊     | 61/126 [01:21<01:28,  1.37s/it]\u001b[A\n"," 49%|████▉     | 62/126 [01:22<01:27,  1.36s/it]\u001b[A\n"," 50%|█████     | 63/126 [01:24<01:25,  1.36s/it]\u001b[A\n"," 51%|█████     | 64/126 [01:25<01:25,  1.37s/it]\u001b[A\n"," 52%|█████▏    | 65/126 [01:26<01:23,  1.37s/it]\u001b[A\n"," 52%|█████▏    | 66/126 [01:28<01:22,  1.37s/it]\u001b[A\n"," 53%|█████▎    | 67/126 [01:29<01:20,  1.37s/it]\u001b[A\n"," 54%|█████▍    | 68/126 [01:30<01:18,  1.36s/it]\u001b[A\n"," 55%|█████▍    | 69/126 [01:32<01:17,  1.36s/it]\u001b[A\n"," 56%|█████▌    | 70/126 [01:33<01:16,  1.37s/it]\u001b[A\n"," 56%|█████▋    | 71/126 [01:35<01:15,  1.36s/it]\u001b[A\n"," 57%|█████▋    | 72/126 [01:36<01:13,  1.36s/it]\u001b[A\n"," 58%|█████▊    | 73/126 [01:37<01:11,  1.36s/it]\u001b[A\n"," 59%|█████▊    | 74/126 [01:39<01:10,  1.36s/it]\u001b[A\n"," 60%|█████▉    | 75/126 [01:40<01:08,  1.35s/it]\u001b[A\n"," 60%|██████    | 76/126 [01:41<01:07,  1.36s/it]\u001b[A\n"," 61%|██████    | 77/126 [01:43<01:06,  1.36s/it]\u001b[A\n"," 62%|██████▏   | 78/126 [01:44<01:05,  1.36s/it]\u001b[A\n"," 63%|██████▎   | 79/126 [01:45<01:03,  1.36s/it]\u001b[A\n"," 63%|██████▎   | 80/126 [01:47<01:02,  1.35s/it]\u001b[A\n"," 64%|██████▍   | 81/126 [01:48<01:00,  1.35s/it]\u001b[A\n"," 65%|██████▌   | 82/126 [01:50<00:59,  1.36s/it]\u001b[A\n"," 66%|██████▌   | 83/126 [01:51<00:58,  1.35s/it]\u001b[A\n"," 67%|██████▋   | 84/126 [01:52<00:57,  1.36s/it]\u001b[A\n"," 67%|██████▋   | 85/126 [01:54<00:55,  1.36s/it]\u001b[A\n"," 68%|██████▊   | 86/126 [01:55<00:54,  1.36s/it]\u001b[A\n"," 69%|██████▉   | 87/126 [01:56<00:52,  1.36s/it]\u001b[A\n"," 70%|██████▉   | 88/126 [01:58<00:51,  1.36s/it]\u001b[A\n"," 71%|███████   | 89/126 [01:59<00:50,  1.35s/it]\u001b[A\n"," 71%|███████▏  | 90/126 [02:00<00:48,  1.36s/it]\u001b[A\n"," 72%|███████▏  | 91/126 [02:02<00:47,  1.36s/it]\u001b[A\n"," 73%|███████▎  | 92/126 [02:03<00:46,  1.36s/it]\u001b[A\n"," 74%|███████▍  | 93/126 [02:04<00:45,  1.36s/it]\u001b[A\n"," 75%|███████▍  | 94/126 [02:06<00:43,  1.36s/it]\u001b[A\n"," 75%|███████▌  | 95/126 [02:07<00:42,  1.37s/it]\u001b[A\n"," 76%|███████▌  | 96/126 [02:09<00:41,  1.37s/it]\u001b[A\n"," 77%|███████▋  | 97/126 [02:10<00:39,  1.37s/it]\u001b[A\n"," 78%|███████▊  | 98/126 [02:11<00:38,  1.36s/it]\u001b[A\n"," 79%|███████▊  | 99/126 [02:13<00:36,  1.36s/it]\u001b[A\n"," 79%|███████▉  | 100/126 [02:14<00:35,  1.36s/it]\u001b[A\n"," 80%|████████  | 101/126 [02:15<00:34,  1.36s/it]\u001b[A\n"," 81%|████████  | 102/126 [02:17<00:32,  1.37s/it]\u001b[A\n"," 82%|████████▏ | 103/126 [02:18<00:31,  1.36s/it]\u001b[A\n"," 83%|████████▎ | 104/126 [02:19<00:29,  1.36s/it]\u001b[A\n"," 83%|████████▎ | 105/126 [02:21<00:28,  1.36s/it]\u001b[A\n"," 84%|████████▍ | 106/126 [02:22<00:27,  1.37s/it]\u001b[A\n"," 85%|████████▍ | 107/126 [02:24<00:25,  1.37s/it]\u001b[A\n"," 86%|████████▌ | 108/126 [02:25<00:24,  1.36s/it]\u001b[A\n"," 87%|████████▋ | 109/126 [02:26<00:23,  1.36s/it]\u001b[A\n"," 87%|████████▋ | 110/126 [02:28<00:21,  1.36s/it]\u001b[A\n"," 88%|████████▊ | 111/126 [02:29<00:20,  1.36s/it]\u001b[A\n"," 89%|████████▉ | 112/126 [02:30<00:19,  1.36s/it]\u001b[A\n"," 90%|████████▉ | 113/126 [02:32<00:17,  1.36s/it]\u001b[A\n"," 90%|█████████ | 114/126 [02:33<00:16,  1.37s/it]\u001b[A\n"," 91%|█████████▏| 115/126 [02:34<00:15,  1.37s/it]\u001b[A\n"," 92%|█████████▏| 116/126 [02:36<00:13,  1.37s/it]\u001b[A\n"," 93%|█████████▎| 117/126 [02:37<00:12,  1.36s/it]\u001b[A\n"," 94%|█████████▎| 118/126 [02:39<00:10,  1.37s/it]\u001b[A\n"," 94%|█████████▍| 119/126 [02:40<00:09,  1.37s/it]\u001b[A\n"," 95%|█████████▌| 120/126 [02:41<00:08,  1.36s/it]\u001b[A\n"," 96%|█████████▌| 121/126 [02:43<00:06,  1.36s/it]\u001b[A\n"," 97%|█████████▋| 122/126 [02:44<00:05,  1.36s/it]\u001b[A\n"," 98%|█████████▊| 123/126 [02:45<00:04,  1.37s/it]\u001b[A\n"," 98%|█████████▊| 124/126 [02:47<00:02,  1.36s/it]\u001b[A\n"," 99%|█████████▉| 125/126 [02:48<00:01,  1.35s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["[MoviePy] Done.\n","[MoviePy] >>>> Video ready: /content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Output/movie_track_kf_out.mp4 \n","\n","CPU times: user 5min 5s, sys: 6.93 s, total: 5min 12s\n","Wall time: 2min 50s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Okqy6ruRGFN_","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597755510216,"user_tz":-120,"elapsed":95918,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":["import io\n","import base64\n","from IPython.display import HTML\n","\n","video = io.open('/content/drive/My Drive/Think Autonomous/SDC Course/Tracking/Output/movie_track_kf.mp4', 'r+b').read()\n","encoded = base64.b64encode(video)\n","HTML(data='''<video alt=\"test\" controls width=\"320\" height=\"240\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exl0dVq2lXJL","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597755510217,"user_tz":-120,"elapsed":95917,"user":{"displayName":"Jeremy Cohen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjuXVLXv4h_4amPyg1hbNm21-guh4HaXmiGnaeUnA=s64","userId":"01957346698928395081"}}},"source":[""],"execution_count":null,"outputs":[]}]}